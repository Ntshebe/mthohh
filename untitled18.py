# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xdL7sEMAjKO5uwX4ywjqBv7K0nR3B3ko
"""

!pip install prophet

!pip install faker

import pandas as pd
import numpy as np
from faker import Faker
import random

fake = Faker()
np.random.seed(42)

# --- Patients Table ---
num_patients = 500
patients = pd.DataFrame({
    'patient_id': range(1, num_patients + 1),
    'name': [fake.name() for _ in range(num_patients)],
    'age': np.random.randint(18, 80, num_patients),
    'gender': np.random.choice(['Male', 'Female'], num_patients),
    'department': np.random.choice(['ENT', 'PPT', 'TB Focal Point'], num_patients)
})

visits = []
for pid in patients['patient_id']:
    for _ in range(random.randint(1, 4)):
        visits.append({
            'visit_id': len(visits) + 1,
            'patient_id': pid,
            'visit_date': fake.date_between(start_date='-1y', end_date='today'),
            'symptom_score': np.random.randint(1, 10)
        })
visits = pd.DataFrame(visits)

# --- Diagnoses Table ---
diagnoses = pd.DataFrame({
    'visit_id': visits['visit_id'],
    'diagnosis': np.random.choice(['Normal', 'Mild', 'Severe'], len(visits))
})

# --- Outcomes Table (Classification Target) ---
outcomes = pd.DataFrame({
    'visit_id': visits['visit_id'],
    'outcome': np.where(visits['symptom_score'] > 6, 'Referral', 'Recovered')
})

# --- Save to CSV ---
patients.to_csv("patients.csv", index=False)
visits.to_csv("visits.csv", index=False)
diagnoses.to_csv("diagnoses.csv", index=False)
outcomes.to_csv("outcomes.csv", index=False)

"""understand data

"""

# Check for missing values
print("Missing values in patients:\n", patients.isnull().sum())
print("Missing values in visits:\n", visits.isnull().sum())
print("Missing values in diagnoses:\n", diagnoses.isnull().sum())
print("Missing values in outcomes:\n", outcomes.isnull().sum())

# Drop duplicates if any
patients.drop_duplicates(inplace=True)
visits.drop_duplicates(inplace=True)
diagnoses.drop_duplicates(inplace=True)
outcomes.drop_duplicates(inplace=True)

# Convert visit_date to datetime
visits['visit_date'] = pd.to_datetime(visits['visit_date'])

# Merge visits with diagnoses and outcomes
visit_data = visits.merge(diagnoses, on='visit_id').merge(outcomes, on='visit_id')

# Merge with patients
full_data = visit_data.merge(patients, on='patient_id')

# Preview final dataset
print("Merged Dataset:")
print(full_data.head())

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.countplot(data=full_data, x='department', palette='Set2')
plt.title("Patient Count by Department")
plt.xlabel("Department")
plt.ylabel("Number of Patients")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.boxplot(data=full_data, x='outcome', y='symptom_score', palette='coolwarm')
plt.title("Symptom Score by Outcome")
plt.xlabel("Outcome")
plt.ylabel("Symptom Score")
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(data=full_data, x='diagnosis', palette='pastel')
plt.title("Diagnosis Distribution")
plt.xlabel("Diagnosis")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(data=full_data, x='age', hue='outcome', multiple='stack', bins=15, palette='muted')
plt.title("Age Distribution by Outcome")
plt.xlabel("Age")
plt.ylabel("Number of Visits")
plt.tight_layout()
plt.show()

monthly_visits = full_data.copy()
monthly_visits['month'] = monthly_visits['visit_date'].dt.to_period('M').astype(str)

plt.figure(figsize=(10,4))
sns.countplot(data=monthly_visits, x='month', palette='viridis')
plt.title("Monthly Visit Volume")
plt.xlabel("Month")
plt.ylabel("Number of Visits")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

features = ['age', 'gender', 'department', 'symptom_score', 'diagnosis']
target = 'outcome'

df_model = full_data[features + [target]].copy()

# Label encode categorical columns
label_cols = ['gender', 'department', 'diagnosis', 'outcome']
le_dict = {}

for col in label_cols:
    le = LabelEncoder()
    df_model[col] = le.fit_transform(df_model[col])
    le_dict[col] = le  # Save encoder for later use

# --- Train-Test Split ---
X = df_model.drop(columns=[target])
y = df_model[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# --- Predict on Test Set ---
y_pred = clf.predict(X_test)

# --- Evaluate Accuracy ---
acc = accuracy_score(y_test, y_pred)
print("Accuracy Score:", round(acc, 3))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# --- Confusion Matrix ---
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Aggregate visit counts per month
monthly_data = full_data.copy()
monthly_data['month'] = monthly_data['visit_date'].dt.to_period('M').astype(str)
monthly_counts = monthly_data.groupby('month').size().reset_index(name='visits')

# Convert to Prophet format
df_prophet = monthly_counts.rename(columns={'month': 'ds', 'visits': 'y'})
df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])

print(df_prophet.head())

from prophet import Prophet

# Initialize and train model
model = Prophet()
model.fit(df_prophet)

# Create future dataframe (next 6 months)
future = model.make_future_dataframe(periods=6, freq='M')

# Forecast
forecast = model.predict(future)

# Show forecast
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

from prophet.plot import plot_plotly

fig = plot_plotly(model, forecast)
fig.show()

# Save forecast to CSV
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].to_csv("forecast.csv", index=False)

import joblib

# Save trained model
joblib.dump(model, "prophet_model.pkl")

from google.colab import files

# Download both files
files.download("forecast.csv")
files.download("prophet_model.pkl")

# Save merged dataset to CSV
full_data.to_csv("full_data.csv", index=False)

from google.colab import files

# Download to your computer
files.download("full_data.csv")